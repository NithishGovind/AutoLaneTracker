{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# # Yellow Detection\n",
    "# \n",
    "# This script sets up a camera feed and processes the frames to detect yellow lanes.\n",
    "# It adjusts the car's steering based on the detected lane's position.\n"
   ],
   "id": "eecfec9a7da456fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import cv2\n",
    "import numpy as np\n"
   ],
   "id": "381be4f90ff02ea3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Importing the CSICamera class from the jetcam library to initialize and control the camera.\n",
    "from jetcam.csi_camera import CSICamera\n",
    "\n",
    "# Initialize the camera with a resolution of 224x224.\n",
    "camera = CSICamera(width=224, height=224)\n"
   ],
   "id": "13ce3379bd352559"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Start the camera feed.\n",
    "camera.running = True\n"
   ],
   "id": "5aedc31bd53f14a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Import the NvidiaRacecar class to control the car.\n",
    "from jetracer.nvidia_racecar import NvidiaRacecar\n",
    "car = NvidiaRacecar()\n"
   ],
   "id": "edee7ea2bdac0a47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Define the HSV range for the yellow color\n",
    "# \n",
    "# Setting the lower and upper bounds for the yellow color in HSV format to detect yellow lanes.\n"
   ],
   "id": "865c9bbfa4e859af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "LOWER_YELLOW_HSV = np.array([11, 80, 87])\n",
    "UPPER_YELLOW_HSV = np.array([22, 136, 182])\n"
   ],
   "id": "70ccaaca66beb05d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Smoothing factor for center point calculation\n",
    "# \n",
    "# ALPHA is a smoothing factor used to average the current center point with the previous center point for smoother steering.\n"
   ],
   "id": "c44aa2fb21708771"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "ALPHA = 0.2\n"
   ],
   "id": "5af896d109b95624"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Initialize previous center point\n",
    "# \n",
    "# `prev_center` keeps track of the previous center point of the detected lane for smoothing purposes.\n"
   ],
   "id": "bf8c857ccce07382"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "prev_center = None\n"
   ],
   "id": "6d9c0dbcd8425e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Create an image widget to display the contours.\n",
    "contour_widget = ipywidgets.Image(format='jpeg', width=camera.width, height=camera.height)\n"
   ],
   "id": "8275b25aa4ee4d87"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Create image preview widget, Display the camera widget\n",
    "# \n",
    "# Setting up the widget to display the camera feed in the Jupyter notebook.\n"
   ],
   "id": "1b63af614c970560"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "camera_widget = ipywidgets.Image(width=camera.width, height=camera.height)\n",
    "traitlets.dlink((camera, 'value'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "display(camera_widget)\n"
   ],
   "id": "8bcde16f4c86c753"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# # Display sliders for steering gain, bias, and throttle\n",
    "# \n",
    "# Creating sliders for adjusting the car's steering gain, bias, and throttle in real-time.\n"
   ],
   "id": "1ae0a3c5f7c351cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "steering_gain_slider = ipywidgets.FloatSlider(description='Steering Gain', min=-1.0, max=1.0, value=-0.7, step=0.01, orientation='horizontal', layout={'width': '300px'})\n",
    "steering_bias_slider = ipywidgets.FloatSlider(description='Steering Bias', min=-0.5, max=0.5, value=0.0, step=0.01, orientation='horizontal', layout={'width': '300px'})\n",
    "steering_value_slider = ipywidgets.FloatSlider(description='Steering', min=-1.0, max=1.0, value=0, step=0.01, orientation='horizontal', disabled=False, layout={'width': '400px'})\n",
    "throttle_slider = ipywidgets.FloatSlider(description='Throttle', min=-1.0, max=1.0, value=0.15, step=0.01, orientation='vertical')\n",
    "\n",
    "# Link sliders to car properties\n",
    "steering_gain_link = traitlets.link((steering_gain_slider, 'value'), (car, 'steering_gain'))\n",
    "steering_offset_link = traitlets.link((steering_bias_slider, 'value'), (car, 'steering_offset'))\n",
    "throttle_slider_link = traitlets.link((throttle_slider, 'value'), (car, 'throttle'))\n",
    "\n",
    "# Display the sliders and camera widgets in a horizontal box layout.\n",
    "display(ipywidgets.HBox([\n",
    "    ipywidgets.VBox([steering_gain_slider, steering_bias_slider, steering_value_slider]),\n",
    "    throttle_slider, camera_widget, contour_widget\n",
    "]))\n"
   ],
   "id": "5c826d95d09f542d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Function to map value ranges\n",
    "# \n",
    "# Helper function to map a value from one range to another. This is used to map the detected center point to steering values.\n"
   ],
   "id": "f87cf65ec5f919f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def map_value(value, from_low, from_high, to_low, to_high):\n",
    "    if value is None:\n",
    "        return None\n",
    "    return (value - from_low) * (to_high - to_low) / (from_high - from_low) + to_low\n"
   ],
   "id": "6e014c09f6d885a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Function to process frame and detect lane\n",
    "# \n",
    "# Main function to process each frame from the camera. It detects yellow lanes, calculates the center of the lanes, and draws the lane lines and center point on the frame.\n"
   ],
   "id": "40d0de38451d7b83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the lower and upper bounds for yellow color in HSV\n",
    "LOWER_YELLOW_HSV = np.array([20, 100, 100])\n",
    "UPPER_YELLOW_HSV = np.array([30, 255, 255])\n",
    "\n",
    "# Parameters for center smoothing\n",
    "ALPHA = 0.5\n",
    "prev_center = None\n",
    "\n",
    "def process_frame(frame):\n",
    "    global prev_center\n",
    "\n",
    "    # Convert frame to HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Threshold the HSV image to get only yellow colors\n",
    "    yellow_mask = cv2.inRange(hsv, LOWER_YELLOW_HSV, UPPER_YELLOW_HSV)\n",
    "\n",
    "    # Apply Gaussian blur to smooth the mask\n",
    "    blurred = cv2.GaussianBlur(yellow_mask, (5, 5), 0)\n",
    "\n",
    "    # Define the region of interest (ROI)\n",
    "    height, width, _ = frame.shape\n",
    "    roi_vertices = [\n",
    "        (0, height),\n",
    "        (0, height // 2),\n",
    "        (width, height // 2),\n",
    "        (width, height)\n",
    "    ]\n",
    "    mask = np.zeros_like(blurred)\n",
    "    cv2.fillPoly(mask, np.array([roi_vertices], np.int32), 255)\n",
    "    masked_blurred = cv2.bitwise_and(blurred, mask)\n",
    "\n",
    "    # Edge detection using Canny\n",
    "    edges = cv2.Canny(masked_blurred, 50, 150)\n",
    "\n",
    "    # Hough Line Transform to detect lines\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=50, minLineLength=50, maxLineGap=20)\n",
    "\n",
    "    # Create a blank image with the same dimensions as the original frame\n",
    "    lane_image = np.copy(frame)\n",
    "\n",
    "    # Initialize lists to store the coordinates of the leftmost and rightmost lines\n",
    "    left_lines = []\n",
    "    right_lines = []\n",
    "\n",
    "    # Initialize center coordinates\n",
    "    center_x = None\n",
    "    center_y = None\n",
    "\n",
    "    # Draw the lines on the blank image and store the leftmost and rightmost lines\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                if y1 > height // 2 and y2 > height // 2:  # Filter lines in the ROI\n",
    "                    if x1 < width // 2 and x2 < width // 2:\n",
    "                        left_lines.append((x1, y1, x2, y2))\n",
    "                    elif x1 > width // 2 and x2 > width // 2:\n",
    "                        right_lines.append((x1, y1, x2, y2))\n",
    "\n",
    "    # Draw the leftmost line\n",
    "    if left_lines:\n",
    "        left_line = sorted(left_lines, key=lambda line: line[0])[0]\n",
    "        cv2.line(lane_image, (left_line[0], left_line[1]), (left_line[2], left_line[3]), (0, 255, 0), 5)\n",
    "\n",
    "    # Draw the rightmost line\n",
    "    if right_lines:\n",
    "        right_line = sorted(right_lines, key=lambda line: line[0])[-1]\n",
    "        cv2.line(lane_image, (right_line[0], right_line[1]), (right_line[2], right_line[3]), (0, 255, 0), 5)\n",
    "\n",
    "    # Fill the area between the leftmost and rightmost lines\n",
    "    if left_lines and right_lines:\n",
    "        pts = np.array([\n",
    "            [left_line[0], left_line[1]],\n",
    "            [left_line[2], left_line[3]],\n",
    "            [right_line[2], right_line[3]],\n",
    "            [right_line[0], right_line[1]]\n",
    "        ])\n",
    "        cv2.fillPoly(lane_image, [pts], (0, 255, 0))\n",
    "\n",
    "        # Calculate the center point between the two lines\n",
    "        center_x = (left_line[0] + left_line[2] + right_line[0] + right_line[2]) // 4\n",
    "        center_y = (left_line[1] + left_line[3] + right_line[1] + right_line[3]) // 4\n",
    "\n",
    "        # Smoothing the center point\n",
    "        if prev_center is not None:\n",
    "            center_x = int(ALPHA * center_x + (1 - ALPHA) * prev_center[0])\n",
    "            center_y = int(ALPHA * center_y + (1 - ALPHA) * prev_center[1])\n",
    "\n",
    "        prev_center = (center_x, center_y)\n",
    "\n",
    "        # Ensure the center point is within the ROI\n",
    "        if center_y > height // 2:\n",
    "            # Draw a circle at the center point\n",
    "            cv2.circle(lane_image, (center_x, center_y), 15, (0, 0, 255), -1)\n",
    "    else:\n",
    "        if prev_center is not None:\n",
    "            center_x, center_y = prev_center\n",
    "\n",
    "    # Extract and draw contours\n",
    "    contours, _ = cv2.findContours(yellow_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_image = np.zeros_like(frame)\n",
    "    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Calculate the center of the detected lanes\n",
    "    if contours:\n",
    "        bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "        x_centers = [(x + w // 2) for x, y, w, h in bounding_boxes]\n",
    "        y_centers = [(y + h // 2) for x, y, w, h in bounding_boxes]\n",
    "\n",
    "        if x_centers and y_centers:\n",
    "            avg_x = int(sum(x_centers) / len(x_centers))\n",
    "            avg_y = int(sum(y_centers) / len(y_centers))\n",
    "            cv2.circle(contour_image, (avg_x, avg_y), 10, (0, 0, 255), -1)\n",
    "            center_coordinates = (avg_x, avg_y)\n",
    "        else:\n",
    "            center_coordinates = (0, 0)\n",
    "    else:\n",
    "        center_coordinates = (0, 0)\n",
    "\n",
    "    return lane_image, contour_image, center_coordinates\n"
   ],
   "id": "bc5ed03599238fa8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Function to update the car's steering based on the center point\n",
    "# \n",
    "# This function updates the car's steering value based on the center point of the detected lane.\n",
    "# It uses the `map_value` function to convert the center point to a steering value and updates the car's steering.\n"
   ],
   "id": "142bb427f7ccd2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def update_frame(change):\n",
    "    frame = change['new']\n",
    "    processed_frame, another, center = process_frame(frame)\n",
    "\n",
    "    if center[0] is not None:\n",
    "        x = map_value(center[0], 0, camera.width, -1.0, 1.0)\n",
    "        steering = (x * steering_gain_slider.value + steering_bias_slider.value) * -1\n",
    "        steering = max(min(steering, 1.0), -1.0)\n",
    "        steering_value_slider.value = steering\n",
    "        car.steering = steering\n",
    "        contour_widget.value = bgr8_to_jpeg(another)\n",
    "\n",
    "    camera_widget.value = bgr8_to_jpeg(processed_frame)\n"
   ],
   "id": "f70dd3b7f19c16e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Observe changes in the camera feed and call `update_frame` function to process each frame.\n",
    "camera.observe(update_frame, names='value')\n"
   ],
   "id": "41b57c335693d469"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "\n",
   "id": "47bd69aa25350dab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
